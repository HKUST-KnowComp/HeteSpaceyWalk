/*
------------------------------------------------------------------------------------------------------------------------------------------------
The metapath2vec code is built upon Mikolov et al.'s word2vec.c from https://code.google.com/archive/p/word2vec/

------------------------------------------------------------------------------------------------------------------------------------------------
*/

metapath2vec bibtex information
------------------------------------------------
@inproceedings{metapath2vec:KDD17,
 title={metapath2vec: Scalable Representation Learning for Heterogeneous Networks},
 author = {Dong, Yuxiao and Chawla, Nitesh V and Swami, Ananthram},
 booktitle = {KDD '17},
 year = {2017},
 pages = {135--144},
 publisher = {ACM}
} 
------------------------------------------------

Compile:
	1.  cmd "make" in folder code_metapath2vec/
	2.  run "metapath2vec" in folder code_metapath2vec/

Usage: ./metapath2vec [options] 
The Options follow Mikolov et al.'s word2vec
Options for training:
	-train <file>
		Use text data from <file> to train the model
	-output <file>
		Use <file> to save the resulting word vectors / word clusters
	-size <int>
		Set size of word vectors; default is 100
	-window <int>
		Set max skip length between words; default is 5
	-sample <float>
		Set threshold for occurrence of words. Those that appear with higher frequency in the training data
		will be randomly down-sampled; default is 1e-3, useful range is (0, 1e-5)
	-pp <int>
		Use metapath2vec++ or metapath2vec; default is 1 (metapath2vec++); for metapath2vec, use 0
	-negative <int>
		Number of negative examples; default is 5, common values are 3 - 10 (0 = not used)
	-threads <int>
		Use <int> threads (default 12)
	-iter <int>
		Run more training iterations (default 5)
	-min-count <int>
		This will discard words that appear less than <int> times; default is 5
	-alpha <float>
		Set the starting learning rate; default is 0.025 for skip-gram
	-classes <int>
		Output word classes rather than word vectors; default number of classes is 0 (vectors are written)
	-debug <int>
		Set the debug mode (default = 2 = more info during training)
	-save-vocab <file>
		The vocabulary will be saved to <file>
	-read-vocab <file>
		The vocabulary will be read from <file>, not constructed from the training data

Examples:
./metapath2vec -train ../in_dbis/dbis.cac.w1000.l100.txt -output ../out_dbis/dbis.cac.w1000.l100 -pp 1 -size 128 -window 7 -negative 5 -threads 32

Input: 
	The paths generated by random walks, each of which consists of different types of nodes. An example can be found in ../in_dbis/dbis.cac.w1000.l100.txt
	Currently, the code supports four types of nodes: 
		1. one starting from "v", e.g., vKDD
		2. one starting from "a", e.g., aJiaweiHan
		3. one starting from "i"
		4. one starting from "f"

Output:
	1. one vector file for each node in binary format 		(e.g., dbis.cac.w1000.l100)
	2. the same vector file for each node in text format 	(e.g., dbis.cac.w1000.l100.txt)
			



